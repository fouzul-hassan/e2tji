{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Processed Data EDA (PyTorch .pt files)\n",
                "\n",
                "This notebook analyzes the **pre-processed** ZuCo data (no null sentences, clean format).\n",
                "\n",
                "Run this after `prepare_pytorch_data.py` to visualize the processed data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "from collections import Counter\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Style\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "sns.set_palette('husl')\n",
                "\n",
                "print(\"Libraries loaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Processed Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_dir = Path('./data/processed')\n",
                "\n",
                "train_data = torch.load(data_dir / 'train_data.pt', weights_only=False)\n",
                "val_data = torch.load(data_dir / 'val_data.pt', weights_only=False)\n",
                "test_data = torch.load(data_dir / 'test_data.pt', weights_only=False)\n",
                "\n",
                "print(f\"✓ Train: {train_data['eeg'].shape[0]:,} samples\")\n",
                "print(f\"✓ Val: {val_data['eeg'].shape[0]:,} samples\")\n",
                "print(f\"✓ Test: {test_data['eeg'].shape[0]:,} samples\")\n",
                "print(f\"✓ Total: {train_data['eeg'].shape[0] + val_data['eeg'].shape[0] + test_data['eeg'].shape[0]:,} samples\")\n",
                "print(f\"✓ EEG shape: {train_data['eeg'].shape[1:]} (channels, time)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Subject & Text Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subject analysis\n",
                "all_subjects = train_data['subjects'] + val_data['subjects'] + test_data['subjects']\n",
                "subject_counts = Counter(all_subjects)\n",
                "print(f\"Total unique subjects: {len(subject_counts)}\")\n",
                "print(f\"Subjects: {sorted(subject_counts.keys())}\")\n",
                "\n",
                "# Text analysis\n",
                "all_texts = train_data['texts'] + val_data['texts'] + test_data['texts']\n",
                "word_counts = [len(t.split()) for t in all_texts]\n",
                "\n",
                "print(f\"\\nText Statistics:\")\n",
                "print(f\"  Mean words/sentence: {np.mean(word_counts):.1f}\")\n",
                "print(f\"  Std words: {np.std(word_counts):.1f}\")\n",
                "print(f\"  Min words: {min(word_counts)}\")\n",
                "print(f\"  Max words: {max(word_counts)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Comprehensive Visualizations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Brain region mapping\n",
                "BRAIN_REGIONS = {\n",
                "    'Prefrontal L': list(range(0, 11)),\n",
                "    'Prefrontal R': list(range(11, 22)),\n",
                "    'Frontal L': list(range(22, 33)),\n",
                "    'Frontal R': list(range(33, 44)),\n",
                "    'Central L': list(range(44, 55)),\n",
                "    'Central R': list(range(55, 66)),\n",
                "    'Temporal L': list(range(66, 77)),\n",
                "    'Temporal R': list(range(77, 88)),\n",
                "    'Parietal-Occ L': list(range(88, 97)),\n",
                "    'Parietal-Occ R': list(range(97, 105)),\n",
                "}\n",
                "\n",
                "fig = plt.figure(figsize=(16, 14))\n",
                "\n",
                "# --- 1. Split Distribution ---\n",
                "ax1 = fig.add_subplot(3, 3, 1)\n",
                "splits = ['Train', 'Val', 'Test']\n",
                "sizes = [train_data['eeg'].shape[0], val_data['eeg'].shape[0], test_data['eeg'].shape[0]]\n",
                "colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
                "ax1.pie(sizes, labels=splits, autopct='%1.1f%%', colors=colors, startangle=90)\n",
                "ax1.set_title('Dataset Split Distribution', fontweight='bold')\n",
                "\n",
                "# --- 2. Samples per Subject ---\n",
                "ax2 = fig.add_subplot(3, 3, 2)\n",
                "subjects_sorted = sorted(subject_counts.keys())\n",
                "counts = [subject_counts[s] for s in subjects_sorted]\n",
                "ax2.bar(range(len(subjects_sorted)), counts, color='steelblue', alpha=0.8)\n",
                "ax2.set_xticks(range(len(subjects_sorted)))\n",
                "ax2.set_xticklabels(subjects_sorted, rotation=45, ha='right', fontsize=7)\n",
                "ax2.set_xlabel('Subject ID')\n",
                "ax2.set_ylabel('Number of Sentences')\n",
                "ax2.set_title('Samples per Subject', fontweight='bold')\n",
                "\n",
                "# --- 3. Word Count Distribution ---\n",
                "ax3 = fig.add_subplot(3, 3, 3)\n",
                "ax3.hist(word_counts, bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
                "ax3.axvline(np.mean(word_counts), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(word_counts):.1f}')\n",
                "ax3.set_xlabel('Words per Sentence')\n",
                "ax3.set_ylabel('Frequency')\n",
                "ax3.set_title('Sentence Length Distribution', fontweight='bold')\n",
                "ax3.legend()\n",
                "\n",
                "# --- 4. Sample EEG Signal ---\n",
                "ax4 = fig.add_subplot(3, 3, 4)\n",
                "sample_eeg = train_data['eeg'][0].numpy()\n",
                "for ch in [0, 25, 50, 75, 100]:\n",
                "    ax4.plot(sample_eeg[ch, :200], alpha=0.7, linewidth=0.8, label=f'Ch {ch}')\n",
                "ax4.set_xlabel('Time (samples)')\n",
                "ax4.set_ylabel('Amplitude')\n",
                "ax4.set_title('Sample EEG Signal (Multiple Channels)', fontweight='bold')\n",
                "ax4.legend(loc='upper right', fontsize=8)\n",
                "\n",
                "# --- 5. EEG Channel Mean/Std ---\n",
                "ax5 = fig.add_subplot(3, 3, 5)\n",
                "eeg_mean = train_data['eeg'].mean(dim=(0, 2)).numpy()\n",
                "eeg_std = train_data['eeg'].std(dim=(0, 2)).numpy()\n",
                "ax5.fill_between(range(105), eeg_mean - eeg_std, eeg_mean + eeg_std, alpha=0.3, color='blue')\n",
                "ax5.plot(eeg_mean, color='blue', linewidth=1)\n",
                "ax5.set_xlabel('Channel')\n",
                "ax5.set_ylabel('Mean ± Std')\n",
                "ax5.set_title('EEG Channel Statistics', fontweight='bold')\n",
                "\n",
                "# --- 6. Brain Region Power ---\n",
                "ax6 = fig.add_subplot(3, 3, 6)\n",
                "region_powers = []\n",
                "for name, channels in BRAIN_REGIONS.items():\n",
                "    power = train_data['eeg'][:, channels, :].abs().mean().item()\n",
                "    region_powers.append(power)\n",
                "ax6.barh(list(BRAIN_REGIONS.keys()), region_powers, color=plt.cm.viridis(np.linspace(0.2, 0.8, 10)))\n",
                "ax6.set_xlabel('Average Power')\n",
                "ax6.set_title('Power by Brain Region', fontweight='bold')\n",
                "\n",
                "# --- 7. EEG Heatmap ---\n",
                "ax7 = fig.add_subplot(3, 3, 7)\n",
                "sample_eeg = train_data['eeg'][42].numpy()\n",
                "im = ax7.imshow(sample_eeg[:, :200], aspect='auto', cmap='RdBu_r', vmin=-3, vmax=3)\n",
                "ax7.set_xlabel('Time (samples)')\n",
                "ax7.set_ylabel('Channel')\n",
                "ax7.set_title('EEG Heatmap (Sample)', fontweight='bold')\n",
                "plt.colorbar(im, ax=ax7, label='Amplitude')\n",
                "\n",
                "# --- 8. Text Length vs EEG Power ---\n",
                "ax8 = fig.add_subplot(3, 3, 8)\n",
                "n_samples = min(500, len(train_data['texts']))\n",
                "sample_wc = [len(train_data['texts'][i].split()) for i in range(n_samples)]\n",
                "sample_pw = [train_data['eeg'][i].abs().mean().item() for i in range(n_samples)]\n",
                "ax8.scatter(sample_wc, sample_pw, alpha=0.5, c='purple', s=20)\n",
                "ax8.set_xlabel('Words in Sentence')\n",
                "ax8.set_ylabel('EEG Power')\n",
                "ax8.set_title('Text Length vs EEG Power', fontweight='bold')\n",
                "\n",
                "# --- 9. Sample Texts ---\n",
                "ax9 = fig.add_subplot(3, 3, 9)\n",
                "ax9.axis('off')\n",
                "ax9.set_title('Sample Sentences', fontweight='bold')\n",
                "sample_texts = \"\\n\\n\".join([f\"[{i+1}] {train_data['texts'][i][:60]}...\" for i in range(5)])\n",
                "ax9.text(0.1, 0.9, sample_texts, transform=ax9.transAxes, fontsize=9, \n",
                "         verticalalignment='top', fontfamily='monospace')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('eda_processed_visualization.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n✓ Saved visualization to eda_processed_visualization.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Detailed Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*60)\n",
                "print(\"DETAILED STATISTICS\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "eeg_all = torch.cat([train_data['eeg'], val_data['eeg'], test_data['eeg']], dim=0)\n",
                "print(f\"\\nEEG Data Statistics:\")\n",
                "print(f\"  Shape: {eeg_all.shape}\")\n",
                "print(f\"  Mean: {eeg_all.mean():.4f}\")\n",
                "print(f\"  Std: {eeg_all.std():.4f}\")\n",
                "print(f\"  Min: {eeg_all.min():.4f}\")\n",
                "print(f\"  Max: {eeg_all.max():.4f}\")\n",
                "\n",
                "print(\"\\nSubject Distribution per Split:\")\n",
                "print(f\"  Train: {len(set(train_data['subjects']))} subjects - {sorted(set(train_data['subjects']))}\")\n",
                "print(f\"  Val: {len(set(val_data['subjects']))} subjects - {sorted(set(val_data['subjects']))}\")\n",
                "print(f\"  Test: {len(set(test_data['subjects']))} subjects - {sorted(set(test_data['subjects']))}\")\n",
                "\n",
                "print(\"\\n✅ EDA Complete!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}